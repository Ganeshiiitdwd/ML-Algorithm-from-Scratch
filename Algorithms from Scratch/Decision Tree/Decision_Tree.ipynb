{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "603e022a-aaba-4899-a450-4ada22a3ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from public_tests import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3b3e49-301f-48ee-8df9-1d6843d9f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1,1,1],[1,0,1],[1,0,0],[1,0,0],[1,1,1],[0,1,1],[0,0,0],[1,0,1],[0,1,0],[1,0,0]])\n",
    "y_train = np.array([1,1,0,0,1,0,0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e38240d-2c2e-42ef-aaa3-80e437f74e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the array till 5 is [[1 1 1]\n",
      " [1 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(f'the array till 5 is {X_train[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57adf4a8-2c3a-4f9e-9539-ae1966f434ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (10, 3)\n",
      "Shape of y_train : (10,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of X_train : {X_train.shape}')\n",
    "print(f'Shape of y_train : {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818d23dc-90a1-42ca-9d3f-fea241e2c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining functions \n",
    "#  numpy array (y) that indicates whether the examples in that node are edible (1) or poisonous(0) \n",
    "def compute_entropy(y):\n",
    "    entropy=0\n",
    "    if len(y)!=0:\n",
    "        p1=p1=len(y[y==1])/len(y)    # p1 ,  which is the fraction of examples that are edible (i.e. have value = 1 in y)# our code goes like p1 is equal to length of y where y==1 divided by total length\n",
    "        if p1!=0 and p1!=1:\n",
    "            entropy=-p1*np.log2(p1)-(1-p1)*np.log2(1-p1)\n",
    "        else:\n",
    "            entropy=0\n",
    "    return entropy      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5573a151-cad5-4e64-8fe5-902464b6edf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy at root node  1.0\n"
     ]
    }
   ],
   "source": [
    "# let's test function with data\n",
    "# as at root node we have 5 edible and 5 non-edible mushroom therefore entropy=1\n",
    "# remember u can always dry run #smile\n",
    "print(\"Entropy at root node \", compute_entropy(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55b9c414-45d9-4e3c-9448-8dd758cfd5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset at the node, segrating where that feature is 1 and 0 into left and right branches respectively\n",
    "# #e.g For example, say we're starting at the root node (so node_indices = [0,1,2,3,4,5,6,7,8,9]), and we chose to split on feature 0, which is whether or not the example has a brown cap.\n",
    "# The output of the function is then, left_indices = [0,1,2,3,4,7,9] and right_indices = [5,6,8]\n",
    "\n",
    "def split_dataset(X,node_indices,feature):\n",
    "    left_indices=[]\n",
    "    right_indices=[]\n",
    "\n",
    "\n",
    "    for i in node_indices:\n",
    "        if X[i][feature]==1:\n",
    "            left_indices.append(i)\n",
    "        else:\n",
    "            right_indices.append(i)\n",
    "    return left_indices,right_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282de0f8-8ceb-40ac-ba78-1fc0f2ef7a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left root indices  [0, 1, 2, 3, 4, 7, 9]\n",
      "Right root indices  [5, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "root_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  # as wi have 10 examples\n",
    "# let's do it for feature 0\n",
    "feature=0\n",
    "left_indices,right_indices=split_dataset(X_train,root_indices,feature)\n",
    "\n",
    "print(\"Left root indices \",left_indices)\n",
    "print(\"Right root indices \",right_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a27b81fb-0df8-449f-bba1-614af080b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing function for the information gain\n",
    "def compute_information_Gain(X,y,node_indices,feature):\n",
    "    #splitting the node\n",
    "    left_indices,right_indices= split_dataset(X,node_indices,feature)\n",
    "    #segragating the nodes in the basis of left and right node respectively\n",
    "    X_node,Y_node=X[node_indices],y[node_indices]\n",
    "    x_left,y_left=X[left_indices],y[left_indices]\n",
    "    x_right,y_right=X[right_indices],y[right_indices]\n",
    "\n",
    "    IG=0\n",
    "    # compute entropy of parent node and the childs left and right\n",
    "    node_entropy=compute_entropy(y)\n",
    "    left_entropy=compute_entropy(y_left)\n",
    "    right_entropy=compute_entropy(y_right)\n",
    "    # wleft and wright are the proportion of examples at the left and right branch, respectively\n",
    "    w_left=len(x_left)/len(X)\n",
    "    w_right=len(x_right)/len(X)\n",
    "    # weighted entropy\n",
    "    weighted_entropy=w_left*left_entropy+ w_right*right_entropy\n",
    "    # Information gain\n",
    "\n",
    "    IG=node_entropy-weighted_entropy\n",
    "\n",
    "    return IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99189694-ad91-4839-8bd7-de25b14b1386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG at Brown Cap:  0.034851554559677034\n",
      "IG at Stalk Shape:  0.12451124978365313\n",
      "IG at Solidatory:  0.2780719051126377\n"
     ]
    }
   ],
   "source": [
    "info_gain0= compute_information_Gain(X_train,y_train,root_indices,feature=0)\n",
    "print(\"IG at Brown Cap: \",info_gain0)\n",
    "info_gain1=compute_information_Gain(X_train,y_train,root_indices,feature=1)\n",
    "print(\"IG at Stalk Shape: \",info_gain1)\n",
    "info_gain2=compute_information_Gain(X_train,y_train,root_indices,feature=2)\n",
    "print(\"IG at Solidatory: \",info_gain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "063053c9-a032-4820-ba59-fe09c76b6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn to get dynamically the best decision according to the Information Gain\n",
    "def get_best_split(X,y,node_indices):\n",
    "    best_feature=-1\n",
    "    max_info_gain=0\n",
    "    n=X.shape[1]\n",
    "    for ft in range(n):\n",
    "        info_gain= compute_information_Gain(X,y,node_indices,ft)\n",
    "        if info_gain>max_info_gain:\n",
    "            max_info_gain=info_gain\n",
    "            best_feature=ft\n",
    "    return best_feature\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f816f0d6-42e1-4463-9598-61e2bc0aa2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature to split: 2\n"
     ]
    }
   ],
   "source": [
    "best_feature=get_best_split(X_train,y_train,root_indices)\n",
    "print(f\"Best feature to split: {best_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1435fc4f-5914-4f7b-9fe1-405dffed95ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  building some sort of tree like structure to print our Decision Tree\n",
    "tree=[]\n",
    "def DT(X,y,node_indices,branch_name,max_depth,curr_depth):\n",
    "    if(curr_depth==max_depth):\n",
    "        formatting=\" \"*curr_depth+ \"-\"*curr_depth\n",
    "        print(formatting,\"%s leaf node with Indices\" % branch_name, node_indices)\n",
    "        return\n",
    "    best_feature=get_best_split(X,y,node_indices)\n",
    "    tree.append((curr_depth,branch_name,best_feature,node_indices))\n",
    "    formatting=\"-\"*curr_depth\n",
    "    print(\"%s Depth %d , %s: Split on Feature %d\"%(formatting,curr_depth,branch_name,best_feature))\n",
    "    left_indices, right_indices=split_dataset(X,node_indices,best_feature)\n",
    "    DT(X,y,left_indices,\"Left\",max_depth,curr_depth+1)\n",
    "    DT(X,y,right_indices,\"Right\",max_depth,curr_depth+1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57dcd0d7-a801-437e-aa6d-f336741205a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Depth 0 , Root: Split on Feature 2\n",
      "- Depth 1 , Left: Split on Feature 0\n",
      "  -- Left leaf node with Indices [0, 1, 4, 7]\n",
      "  -- Right leaf node with Indices [5]\n",
      "- Depth 1 , Right: Split on Feature 1\n",
      "  -- Left leaf node with Indices [8]\n",
      "  -- Right leaf node with Indices [2, 3, 6, 9]\n"
     ]
    }
   ],
   "source": [
    "DT(X_train,y_train,root_indices,\"Root\",2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d969a9c-cecc-467b-b90b-30e2739be1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
